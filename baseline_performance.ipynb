{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multitask Baseline Performance\n",
    "\n",
    "In this notebook I will obtain the baseline performances obtainable using simple machine learning on the \"Cookie Theft Picture Test\" section of the DementiaBank dataset. <br />\n",
    "The numerical features are extracted using my feature extraction project [Link here](https://github.com/EdoStoppa/Dementia_Features_Extractor). Furthermore I will define some baseline performance dropping one feature category at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "In this section all the import statements are divided in sub groups to help undestand what each of them does, and to aid an eventual partial run of the notebook (running only Regression, only Binary Classification, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General import useful for each part of the notebook\n",
    "import os\n",
    "import numpy as np\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from typing import Tuple, Callable, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import used to manipulate all the dataset for training/testing purpose\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression Models\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# Regression Models Evaluation\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Models (both Binary and Multi Class)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, BaggingClassifier\n",
    "# Classification Models Evaluation\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to suppress some convergence warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "# Needed to force white background to all plots\n",
    "%config InlineBackend.print_figure_kwargs={'facecolor' : \"w\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preliminary Work\n",
    "This section contains some fuction and variable definition that are useful in the Notebook.<br />\n",
    "Please, check if all the paths are correct for you, and in case they're not, feel free to change them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining some useful variables\n",
    "\n",
    "# Set the project folder\n",
    "PRJ_FOLDER = '.'\n",
    "# Set the folder the full dataset is located\n",
    "DATA_FOLDER = os.path.join(PRJ_FOLDER, 'data')\n",
    "# Set the name of the file that holds the full dataset\n",
    "FULL_DATASET_NAME = 'feature_dataset.csv'\n",
    "# Set the name of the file that holds the angraphic information\n",
    "ANAGRAPHIC_DATASET_NAME = 'anagraphic_info.csv'\n",
    "# Create a list with all the dataset names excluding the full dataset\n",
    "SEP_DATASETS_FOLDER = os.path.join(DATA_FOLDER, 'separate_datasets')\n",
    "# Set the folder where all the results will be saved\n",
    "RES_FOLDER = os.path.join(PRJ_FOLDER, 'results')\n",
    "# Flag needed to explicit if partial datasets should be built\n",
    "BUILD_PARTIAL_DATASET = True\n",
    "\n",
    "print(f'Folder where the entire project is located: {PRJ_FOLDER}')\n",
    "print(f'Folder where the full dataset is saved: {DATA_FOLDER}')\n",
    "print(f'Name of the full dataset: {FULL_DATASET_NAME}')\n",
    "print(f'Name of the anagraphic dataset: {ANAGRAPHIC_DATASET_NAME}')\n",
    "print(f'Separate features group datasets folder: {SEP_DATASETS_FOLDER}')\n",
    "print(f'Folder where all results will be saved: {RES_FOLDER}')\n",
    "print(f'Flag for building partial datasets set to {BUILD_PARTIAL_DATASET}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the names of all elements in the project folder PRJ_FOLDER\n",
    "elements = os.listdir(PRJ_FOLDER)\n",
    "\n",
    "# Fix (if necessary) the folder structure of RES_FOLDER\n",
    "if 'results' not in elements:\n",
    "    os.makedirs(os.path.join(RES_FOLDER, 'regression'))\n",
    "    os.makedirs(os.path.join(RES_FOLDER, 'binary_classification'))\n",
    "    os.makedirs(os.path.join(RES_FOLDER, 'multi_classification3'))\n",
    "    os.makedirs(os.path.join(RES_FOLDER, 'multi_classification4'))\n",
    "    os.makedirs(os.path.join(RES_FOLDER, 'multi_classification5'))\n",
    "else:\n",
    "    if 'regression' not in os.listdir(RES_FOLDER):\n",
    "        os.makedirs(os.path.join(RES_FOLDER, 'regression'))\n",
    "    if 'binary_classification' not in os.listdir(RES_FOLDER):\n",
    "        os.makedirs(os.path.join(RES_FOLDER, 'binary_classification'))\n",
    "    if 'multi_classification3' not in os.listdir(RES_FOLDER):\n",
    "        os.makedirs(os.path.join(RES_FOLDER, 'multi_classification3'))\n",
    "    if 'multi_classification4' not in os.listdir(RES_FOLDER):\n",
    "        os.makedirs(os.path.join(RES_FOLDER, 'multi_classification4'))\n",
    "    if 'multi_classification5' not in os.listdir(RES_FOLDER):\n",
    "        os.makedirs(os.path.join(RES_FOLDER, 'multi_classification5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets Loading\n",
    "In this section there are two functions used to load all the required data, and another function that is used to craft all the partial datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the flag is TRUE, create all the partial datasets and save them in DATA_FOLDER\n",
    "\n",
    "if BUILD_PARTIAL_DATASET:\n",
    "    # Load the full dataset into pandas\n",
    "    full_dataset = pd.read_csv(os.path.join(DATA_FOLDER, FULL_DATASET_NAME))\n",
    "\n",
    "    for to_remove in os.listdir(SEP_DATASETS_FOLDER):\n",
    "        # Avoid removing the anagraphic information\n",
    "        if to_remove != ANAGRAPHIC_DATASET_NAME:\n",
    "            # Get all the names of the features that should be removed\n",
    "            to_remove_dataframe = pd.read_csv(os.path.join(SEP_DATASETS_FOLDER, to_remove))\n",
    "            to_remove_columns = to_remove_dataframe.columns.to_list()[1:]\n",
    "\n",
    "            # Create a partial dataset dataframe\n",
    "            new_dataset = full_dataset.drop(to_remove_columns, axis=1)\n",
    "\n",
    "            # Save the dataset\n",
    "            with open(os.path.join(DATA_FOLDER, f'{to_remove.split(\".\")[0]}_removed.csv'), 'w+') as out:\n",
    "                new_dataset.to_csv(out, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's define a simple function that loads a single dataset\n",
    "\n",
    "def load_raw_data(csv_path: str, feat_to_predict: str) -> Tuple[np.ndarray, np.ndarray, list]:\n",
    "    # Load the entire csv file\n",
    "    data = pd.read_csv(csv_path)\n",
    "\n",
    "    # Get only the labels\n",
    "    labels = pd.DataFrame(data[feat_to_predict], columns=[feat_to_predict])\n",
    "\n",
    "    # Remove the unnecessary columns\n",
    "    data = data.drop(['id', 'mmse', 'bin_class', 'multi_class3', 'multi_class4', 'multi_class5'], axis=1)\n",
    "\n",
    "    return data.to_numpy(), labels.to_numpy().reshape((len(labels), )), data.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function loads all datasets, and make them ready for training/testing\n",
    "\n",
    "def load_processed_data(sep_data_folder: str, data_folder: str, feat_to_predict: str, num_folds: int):\n",
    "    DATASETS = []\n",
    "    FOLDS = []\n",
    "    COLUMNS = []\n",
    "\n",
    "    # Get the name of the folder containing the partial datasets\n",
    "    name_sep_folder = sep_data_folder.split(os.path.sep)[-1]\n",
    "    # Get the name of all datasets present\n",
    "    DATASETS_NAMES = [dataset for dataset in os.listdir(data_folder) if dataset != name_sep_folder]\n",
    "\n",
    "    # Load every dataset \n",
    "    for name in DATASETS_NAMES:\n",
    "        print(f'Loading {name}')\n",
    "        # Get the raw data\n",
    "        data, labels, cols = load_raw_data(os.path.join(data_folder, name), feat_to_predict)\n",
    "        # Create the iterator responsible of dividing the dataset to do KFold cross validation\n",
    "        kfold = StratifiedKFold(n_splits=num_folds)\n",
    "        # Divide the data in training and test set\n",
    "        folds = []\n",
    "        for train_index, test_index in kfold.split(data, labels):\n",
    "            folds.append((train_index, test_index))\n",
    "        \n",
    "        DATASETS.append((data, labels))\n",
    "        FOLDS.append(folds)\n",
    "        COLUMNS.append(cols)\n",
    "    \n",
    "    print('\\nAll data loaded!')\n",
    "    return DATASETS_NAMES, DATASETS, COLUMNS, FOLDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to train both the regression and classification models\n",
    "\n",
    "def train_models(models_generator: Callable[[], Any], datasets: list, datasets_names: list, kfolds: list) -> list:\n",
    "    ready_models = []\n",
    "    for data, data_name, folds in zip(datasets, datasets_names, kfolds):\n",
    "        print(f'Working on {data_name}')\n",
    "\n",
    "        # Unwrap data\n",
    "        dataset, label = data\n",
    "        \n",
    "        # Train a model for each fold\n",
    "        trained_folds = []\n",
    "        for fold in folds:\n",
    "            train_index, _ = fold\n",
    "            X_train, y_train = dataset[train_index], label[train_index]\n",
    "\n",
    "            # Generate new batch of models\n",
    "            models = models_generator()\n",
    "            \n",
    "            fold_models = []\n",
    "            for model, model_name in models:\n",
    "                # Train model\n",
    "                model.fit(X_train, y_train)\n",
    "                # Save model\n",
    "                fold_models.append((model_name, model))\n",
    "\n",
    "            # Save all trained models for the fold\n",
    "            trained_folds.append(fold_models)\n",
    "\n",
    "        # Save all the trained fold models for the daaset\n",
    "        ready_models.append(trained_folds)\n",
    "        print('\\n**********************************************\\n')\n",
    "\n",
    "    return ready_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(lbls: list, avgs: dict, stdevs: dict, y_name: str, title: str, dimensions: tuple, precision=1.0):\n",
    "    # Fix figure dimensions\n",
    "    plt.rcParams[\"figure.figsize\"] = dimensions\n",
    "\n",
    "    # Extract the max value on the Y axis\n",
    "    max_avg_y = max([max(item) for _, item in avgs.items()])\n",
    "    max_stdev_y = max([max(item) for _, item in stdevs.items()])\n",
    "    max_y = np.ceil(max_avg_y) if max_avg_y + max_stdev_y < np.ceil(max_avg_y) else np.ceil(max_avg_y + max_stdev_y)\n",
    "\n",
    "    # Format the data in order to be fed to Pandas\n",
    "    algos = [key for key, _ in avgs.items()]\n",
    "\n",
    "    avgs = [item for _, item in avgs.items()]\n",
    "    avgs = list(map(list, zip(*avgs)))\n",
    "\n",
    "    stdevs = [item for _, item in stdevs.items()]\n",
    "    stdevs = list(map(list, zip(*stdevs)))\n",
    "\n",
    "    # Create positions of the bars\n",
    "    w = 0.12\n",
    "    xticks = [np.arange(len(avgs[0]))]\n",
    "    for _ in range(1, len(avgs)):\n",
    "        xticks.append(xticks[-1] + w)\n",
    "\n",
    "    # Actually plot everything\n",
    "    for values, stdev, pos, lbl in zip(avgs, stdevs, xticks, lbls):\n",
    "        plt.bar(pos, values, w, label=lbl)\n",
    "        plt.errorbar(pos, values, yerr=stdev, fmt=\"o\", ecolor='black', capsize=3, color='black')\n",
    "\n",
    "    # Choose the right position to put the labels on\n",
    "    num_datasets = len(avgs)\n",
    "    if num_datasets % 2 == 0:\n",
    "        idx = num_datasets//2 - 1\n",
    "        pos = xticks[idx] + w/2\n",
    "    else:\n",
    "        idx = (num_datasets - 1) // 2\n",
    "        pos = xticks[idx]\n",
    "\n",
    "    # Fix tile and y/x labels\n",
    "    SMALL_SIZE = 12\n",
    "    MEDIUM_SIZE = 14\n",
    "    BIGGER_SIZE = 20\n",
    "    plt.title(title, fontsize=BIGGER_SIZE)\n",
    "    plt.ylabel(y_name, fontsize=MEDIUM_SIZE)\n",
    "    plt.xlabel('Model', fontsize=MEDIUM_SIZE)\n",
    "    plt.xticks(pos, algos, rotation = 30, fontsize=SMALL_SIZE)\n",
    "    plt.yticks(np.arange(0, max_y, precision), fontsize=SMALL_SIZE)\n",
    "    # Finish everything and show it\n",
    "    plt.legend(fontsize=SMALL_SIZE)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to evaluate the regression models\n",
    "\n",
    "def evaluate_regression_models(ready_models: list, datasets: list, datasets_names: list, kfolds: list) -> list:\n",
    "    evaluation_results = []\n",
    "    avg_to_plot = {name[0]: [] for name in ready_models[0][0]}\n",
    "    std_to_plot = {name[0]: [] for name in ready_models[0][0]}\n",
    "    \n",
    "    for kmodels_matrix, folds, data, name in zip(ready_models, kfolds, datasets, datasets_names):\n",
    "        # Preprocess the name removing the file extension\n",
    "        name = name.split('.')[0]\n",
    "        # Unwrap data\n",
    "        dataset, label = data\n",
    "        \n",
    "        # Reorganize the models\n",
    "        kmodels_matrix = list(map(list, zip(*kmodels_matrix)))\n",
    "        out = ''\n",
    "        for models_list in kmodels_matrix:            \n",
    "            mae, rmse, r2 = [], [], []\n",
    "            for (model_name, model), fold in zip(models_list, folds):\n",
    "                _, test_index = fold\n",
    "                X_test, y_test = dataset[test_index], label[test_index]\n",
    "                # Compute the predictions for the test dataset\n",
    "                predictions = model.predict(X_test)\n",
    "\n",
    "                mae.append(mean_absolute_error(y_test, predictions))\n",
    "                rmse.append(np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "                r2.append(r2_score(y_test, predictions))\n",
    "            \n",
    "            # Compute the average and standard deviation of each metric\n",
    "            mae_avg, mae_std = statistics.mean(mae), statistics.stdev(mae)\n",
    "            rmse_avg, rmse_std = statistics.mean(rmse), statistics.stdev(rmse)\n",
    "            r2_avg, r2_std = statistics.mean(r2), statistics.stdev(r2)\n",
    "\n",
    "            # Save data in dictionary ready to be plotted\n",
    "            avg_to_plot[model_name].append(rmse_avg)\n",
    "            std_to_plot[model_name].append(rmse_std)\n",
    "\n",
    "            # Compute all the interesting metrics\n",
    "            out += f'{model_name}\\n\\n'\n",
    "            out += f'MAE                \\tAvg: {mae_avg:.3f}\\tStdDev: {mae_std:.3f}\\n'\n",
    "            out += f'RMSE               \\tAvg: {rmse_avg:.3f}\\tStdDev: {rmse_std:.3f}\\n'\n",
    "            out += f'R2                 \\tAvg: {r2_avg:.3f}\\tStdDev: {r2_std:.3f}\\n'\n",
    "            out += '\\n****************************************************************\\n\\n'\n",
    "\n",
    "        evaluation_results.append((name, out))\n",
    "\n",
    "    plot_results(datasets_names, avg_to_plot, std_to_plot, 'RMSE', 'Regression Performance', (15,9), precision=0.5)\n",
    "    \n",
    "    return evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_bin(true: np.ndarray, pred: np.ndarray):\n",
    "    acc = accuracy_score(true, pred)\n",
    "    prec = precision_score(true, pred)\n",
    "    rec = recall_score(true, pred)\n",
    "    f1 = f1_score(true, pred)\n",
    "\n",
    "    return acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics_multi(true: np.ndarray, pred: np.ndarray):\n",
    "    mtx = confusion_matrix(true, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to evaluate the binary classification models\n",
    "\n",
    "def evaluate_classification_models(ready_models: list, datasets: list, datasets_names: list, kfolds: list, typ: str, compute_metr: function) -> list:\n",
    "    evaluation_results = []\n",
    "    avg_to_plot = {name[0]: [] for name in ready_models[0][0]}\n",
    "    std_to_plot = {name[0]: [] for name in ready_models[0][0]}\n",
    "    \n",
    "    for kmodels_matrix, folds, data, name in zip(ready_models, kfolds, datasets, datasets_names):\n",
    "        # Preprocess the name removing the file extension\n",
    "        name = name.split('.')[0]\n",
    "        # Unwrap data\n",
    "        dataset, label = data\n",
    "        \n",
    "        # Reorganize the models\n",
    "        kmodels_matrix = list(map(list, zip(*kmodels_matrix)))\n",
    "        out = ''\n",
    "        for models_list in kmodels_matrix:\n",
    "                       \n",
    "            acc, prec, rec, f1 = [], [], [], []\n",
    "            for (model_name, model), fold in zip(models_list, folds):\n",
    "                _, test_index = fold\n",
    "                X_test, y_test = dataset[test_index], label[test_index]\n",
    "                # Compute the predictions for the test dataset\n",
    "                predictions = model.predict(X_test)\n",
    "\n",
    "                metrics = compute_metr(y_test, predictions)\n",
    "                acc.append(metrics[0])\n",
    "                prec.append(metrics[1])\n",
    "                rec.append(metrics[2])\n",
    "                f1.append(metrics[3])\n",
    "            \n",
    "            # Compute the average and standard deviation of each metric\n",
    "            acc_avg, acc_std = statistics.mean(acc), statistics.stdev(acc)\n",
    "            prec_avg, prec_std = statistics.mean(prec), statistics.stdev(prec)\n",
    "            rec_avg, rec_std = statistics.mean(rec), statistics.stdev(rec)\n",
    "            f1_avg, f1_std = statistics.mean(f1), statistics.stdev(f1)\n",
    "\n",
    "            # Save data in dictionary ready to be plotted\n",
    "            avg_to_plot[model_name].append(acc_avg)\n",
    "            std_to_plot[model_name].append(acc_std)\n",
    "\n",
    "            # Compute all the interesting metrics\n",
    "            \n",
    "            out += f'{model_name}\\n\\n'\n",
    "            out += f'Accuracy:          \\tAvg: {acc_avg:.3f}\\tStdDev: {acc_std:.3f}\\n'\n",
    "            out += f'Precision:         \\tAvg: {prec_avg:.3f}\\tStdDev: {prec_std:.3f}\\n'\n",
    "            out += f'Recall:            \\tAvg: {rec_avg:.3f}\\tStdDev: {rec_std:.3f}\\n'\n",
    "            out += f'F1:                \\tAvg: {f1_avg:.3f}\\tStdDev: {f1_std:.3f}\\n'\n",
    "            out += '\\n**********************************************\\n\\n'\n",
    "\n",
    "        evaluation_results.append((name, out))\n",
    "\n",
    "    plot_results(datasets_names, avg_to_plot, std_to_plot, 'Accuracy', f'{typ} Classification Performance', (15,9), precision=0.1)\n",
    "    \n",
    "    return evaluation_results\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function used to save the results in the correct files\n",
    "\n",
    "def save_results(results: list, save_folder: str, task: str):\n",
    "    for name, out in results:\n",
    "        with open(os.path.join(save_folder, task, name), 'w+') as file:\n",
    "            file.write(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "In this section we are going to evalute the performance of different regression models.<br />\n",
    "In particular, we're going to predict the MMSE score of each conversation using these models:\n",
    "- Ridge Regression\n",
    "- KNN Regressor\n",
    "- Boosted Trees\n",
    "- Bagged Trees\n",
    "- Decision Tree\n",
    "- Support Vector Machine Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set some important variables first\n",
    "\n",
    "FEATURE_TO_PREDICT = 'mmse'\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and preparing them for training & testing\n",
    "DATASETS_NAMES, DATASETS, COLUMNS, FOLDS = load_processed_data(SEP_DATASETS_FOLDER, DATA_FOLDER, FEATURE_TO_PREDICT, NUM_FOLDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function that generates a fresh batch of regression models ready to be trained\n",
    "\n",
    "def get_regression_models() -> list:\n",
    "    models = [(Ridge(), 'Ridge Regression'), (KNeighborsRegressor(), 'KNN Regressor'),\n",
    "              (GradientBoostingRegressor(), 'Boosted Trees'), (BaggingRegressor(), 'Bagged Trees'), \n",
    "              (DecisionTreeRegressor(), 'Decision Tree'), (LinearSVR(max_iter=10000), 'SVM')]\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all these regression models\n",
    "trained_regression_models = train_models(get_regression_models, DATASETS, DATASETS_NAMES, FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the models\n",
    "regression_results = evaluate_regression_models(trained_regression_models, DATASETS, DATASETS_NAMES, FOLDS)\n",
    "\n",
    "# Save the results to different files\n",
    "save_results(regression_results, RES_FOLDER, 'regression')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification\n",
    "In this section we are going to evaluate multiple classification models.<br />\n",
    "In particular, we are going to predict if each conversation was made by a patient with Dementia or by a control patient. We will use these models:\n",
    "- Decision Tree\n",
    "- Linear Discriminant Classifier\n",
    "- Logistic Regression\n",
    "- Gaussian Naive Bayes\n",
    "- Linear Support Vector Classifier\n",
    "- K-Nearest Neighbors Classifier\n",
    "- Boosted Trees\n",
    "- Bagged Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set some important variables first\n",
    "\n",
    "FEATURE_TO_PREDICT = 'bin_class'\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and preparing them for training & testing\n",
    "DATASETS_NAMES, DATASETS, COLUMNS, FOLDS = load_processed_data(SEP_DATASETS_FOLDER, DATA_FOLDER, FEATURE_TO_PREDICT, NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function that generates a fresh batch of binary classification models ready to be trained\n",
    "\n",
    "def get_binary_class_models() -> list:\n",
    "    models = [(DecisionTreeClassifier(), 'Decision Trees'), (LinearDiscriminantAnalysis(), 'Linear Discriminant Classifier'),\n",
    "              (LogisticRegression(), 'Logistic Regression'), (GaussianNB(), 'Gaussian Naive Bayes'),\n",
    "              (LinearSVC(max_iter=10000), 'Linear Support Vector Classifier'), (KNeighborsClassifier(), 'KNN Classifier'),\n",
    "              (GradientBoostingClassifier(), 'Boosted Trees'), (BaggingClassifier(), 'Bagged Trees')]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models\n",
    "trained_binary_class_models = train_models(get_binary_class_models, DATASETS, DATASETS_NAMES, FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the models\n",
    "bin_class_results = evaluate_classification_models(trained_binary_class_models, DATASETS, DATASETS_NAMES, FOLDS, 'Binary', 'binary')\n",
    "\n",
    "# Save the results to different files\n",
    "save_results(bin_class_results, RES_FOLDER, 'binary_classification')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi class Classification\n",
    "In this section we introduce a new task: Multi Class classification.<br />\n",
    "We have different version of these multi class labels because there no a single multi label system present in the medical literature. Thus, we create 3 possible version of the labeling that will be examined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Classes\n",
    "- mmse >= 24 --> No Dementia\n",
    "- 18 <= mmse <= 23 --> Dementia\n",
    "- mmse <= 17 --> Severe Dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set some important variables first\n",
    "\n",
    "FEATURE_TO_PREDICT = 'multi_class3'\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and preparing them for training & testing\n",
    "DATASETS_NAMES, DATASETS, COLUMNS, FOLDS = load_processed_data(SEP_DATASETS_FOLDER, DATA_FOLDER, FEATURE_TO_PREDICT, NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function that generates a fresh batch of binary classification models ready to be trained\n",
    "\n",
    "def get_multi_class_models() -> list:\n",
    "    models = [(DecisionTreeClassifier(), 'Decision Trees'), (LinearDiscriminantAnalysis(), 'Linear Discriminant Classifier'),\n",
    "              (LogisticRegression(), 'Logistic Regression'), (GaussianNB(), 'Gaussian Naive Bayes'),\n",
    "              (LinearSVC(max_iter=10000), 'Linear Support Vector Classifier'), (KNeighborsClassifier(), 'KNN Classifier'),\n",
    "              (GradientBoostingClassifier(), 'Boosted Trees'), (BaggingClassifier(), 'Bagged Trees')]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models\n",
    "trained_binary_class_models = train_models(get_multi_class_models, DATASETS, DATASETS_NAMES, FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the models\n",
    "multi_class_results = evaluate_classification_models(trained_binary_class_models, DATASETS, DATASETS_NAMES, FOLDS, 'Multi CLass (3 classes)', 'weighted')\n",
    "\n",
    "# Save the results to different files\n",
    "save_results(multi_class_results, RES_FOLDER, 'multi_classification3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Classes\n",
    "- mmse >= 26 --> No Dementia\n",
    "- 19 <= mmse <= 25 --> Mild Dementia\n",
    "- 10 <= mmse <= 18 --> Dementia\n",
    "- mmse <= 9 --> Severe Dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set some important variables first\n",
    "\n",
    "FEATURE_TO_PREDICT = 'multi_class4'\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and preparing them for training & testing\n",
    "DATASETS_NAMES, DATASETS, COLUMNS, FOLDS = load_processed_data(SEP_DATASETS_FOLDER, DATA_FOLDER, FEATURE_TO_PREDICT, NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function that generates a fresh batch of binary classification models ready to be trained\n",
    "\n",
    "def get_multi_class_models() -> list:\n",
    "    models = [(DecisionTreeClassifier(), 'Decision Trees'), (LinearDiscriminantAnalysis(), 'Linear Discriminant Classifier'),\n",
    "              (LogisticRegression(), 'Logistic Regression'), (GaussianNB(), 'Gaussian Naive Bayes'),\n",
    "              (LinearSVC(max_iter=10000), 'Linear Support Vector Classifier'), (KNeighborsClassifier(), 'KNN Classifier'),\n",
    "              (GradientBoostingClassifier(), 'Boosted Trees'), (BaggingClassifier(), 'Bagged Trees')]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models\n",
    "trained_binary_class_models = train_models(get_multi_class_models, DATASETS, DATASETS_NAMES, FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the models\n",
    "multi_class_results = evaluate_classification_models(trained_binary_class_models, DATASETS, DATASETS_NAMES, FOLDS, 'Multi CLass (4 classes)', 'weighted')\n",
    "\n",
    "# Save the results to different files\n",
    "save_results(multi_class_results, RES_FOLDER, 'multi_classification4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Classes\n",
    "- mmse == 30 --> No Dementia\n",
    "- 26 <= mmse <= 29 --> Possible Dementia\n",
    "- 19 <= mmse <= 25 --> Mild Dementia\n",
    "- 10 <= mmse <= 18 --> Dementia\n",
    "- mmse <= 9 --> Severe Dementia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set some important variables first\n",
    "\n",
    "FEATURE_TO_PREDICT = 'multi_class5'\n",
    "NUM_FOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the datasets and preparing them for training & testing\n",
    "DATASETS_NAMES, DATASETS, COLUMNS, FOLDS = load_processed_data(SEP_DATASETS_FOLDER, DATA_FOLDER, FEATURE_TO_PREDICT, NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function that generates a fresh batch of binary classification models ready to be trained\n",
    "\n",
    "def get_multi_class_models() -> list:\n",
    "    models = [(DecisionTreeClassifier(), 'Decision Trees'), (LinearDiscriminantAnalysis(), 'Linear Discriminant Classifier'),\n",
    "              (LogisticRegression(), 'Logistic Regression'), (GaussianNB(), 'Gaussian Naive Bayes'),\n",
    "              (LinearSVC(max_iter=10000), 'Linear Support Vector Classifier'), (KNeighborsClassifier(), 'KNN Classifier'),\n",
    "              (GradientBoostingClassifier(), 'Boosted Trees'), (BaggingClassifier(), 'Bagged Trees')]\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models\n",
    "trained_binary_class_models = train_models(get_multi_class_models, DATASETS, DATASETS_NAMES, FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all the models\n",
    "multi_class_results = evaluate_classification_models(trained_binary_class_models, DATASETS, DATASETS_NAMES, FOLDS, 'Multi CLass (5 classes)', 'weighted')\n",
    "\n",
    "# Save the results to different files\n",
    "save_results(multi_class_results, RES_FOLDER, 'multi_classification5')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f181d7df2e2b28ffc338bc4e9e62bf8e4913b290cbd3f0fc4616f380690b7e4a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
